{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3627fe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,185,159,151,60,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,222,254,254,254,254,241,198,198,198,198,198,198,198,198,170,52,0,0,0,0,0,0,0,0,0,0,0,0,67,114,72,114,163,227,254,225,254,254,254,250,229,254,254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,66,14,67,67,67,59,21,236,254,106,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,253,209,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,233,255,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,129,254,238,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,59,249,254,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,187,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,205,248,58,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,126,254,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,251,240,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,221,254,166,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,203,254,219,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,254,254,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,224,254,115,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,242,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,254,219,40,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,207,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
      "\n",
      "[[0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.33611765 0.72823529 0.62729412 0.59623529 0.24294118 0.14976471\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.87188235 0.99611765 0.99611765 0.99611765 0.99611765 0.94564706\n",
      "  0.77870588 0.77870588 0.77870588 0.77870588 0.77870588 0.77870588\n",
      "  0.77870588 0.77870588 0.67       0.21188235 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.27011765 0.45258824 0.28952941 0.45258824 0.64282353 0.89129412\n",
      "  0.99611765 0.88352941 0.99611765 0.99611765 0.99611765 0.98058824\n",
      "  0.89905882 0.99611765 0.99611765 0.55352941 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.076\n",
      "  0.26623529 0.06435294 0.27011765 0.27011765 0.27011765 0.23905882\n",
      "  0.09152941 0.92623529 0.99611765 0.42152941 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.33223529 0.99223529 0.82141176 0.07988235 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.09541176\n",
      "  0.91458824 1.         0.33223529 0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.51082353\n",
      "  0.99611765 0.934      0.18082353 0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.23905882 0.97670588\n",
      "  0.99611765 0.25070588 0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.52635294 0.99611765\n",
      "  0.736      0.02941176 0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.04494118 0.80588235 0.97282353\n",
      "  0.23517647 0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.49917647 0.99611765 0.71658824\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.30117647 0.98447059 0.94176471 0.23129412\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.08376471 0.868      0.99611765 0.65447059 0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.02164706 0.79811765 0.99611765 0.86023529 0.14588235 0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.15752941 0.99611765 0.99611765 0.30894118 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.13035294\n",
      "  0.87964706 0.99611765 0.45647059 0.01388235 0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.52635294\n",
      "  0.99611765 0.99611765 0.21188235 0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.24682353 0.94952941\n",
      "  0.99611765 0.99611765 0.21188235 0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.47976471 0.99611765\n",
      "  0.99611765 0.86023529 0.16529412 0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.47976471 0.99611765\n",
      "  0.81364706 0.07988235 0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]\n",
      " [0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01       0.01       0.01\n",
      "  0.01       0.01       0.01       0.01      ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_file = open(\"dataset/mnist_test.csv\")\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()\n",
    "print(len(data_list))\n",
    "print(data_list[0])\n",
    "\n",
    "all_values = data_list[0].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28, 28))\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "\n",
    "scaled_input = image_array / 255.0 * 0.99 + 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414903e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55695413 0.42051683 0.43837513]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55695413, 0.42051683, 0.43837513])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.special\n",
    "import numpy\n",
    "\n",
    "class  NeuralNetWork:\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        #初始化网络，设置输入层，中间层，和输出层节点数\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        #设置学习率\n",
    "        self.lr = learningrate\n",
    "        '''\n",
    "        初始化权重矩阵，我们有两个权重矩阵，一个是wih表示输入层和中间层节点间链路权重形成的矩阵\n",
    "        一个是who,表示中间层和输出层间链路权重形成的矩阵\n",
    "        '''\n",
    "        self.wih = numpy.random.rand(self.hnodes, self.inodes) - 0.5\n",
    "        self.who = numpy.random.rand(self.onodes, self.hnodes) - 0.5\n",
    "\n",
    "        '''\n",
    "        scipy.special.expit对应的是sigmod函数.\n",
    "        lambda是Python关键字，类似C语言中的宏定义，当我们调用self.activation_function(x)时，编译器会把其转换为spicy.special_expit(x)。\n",
    "        '''\n",
    "        self.activation_function = lambda x:scipy.special.expit(x)\n",
    "        pass\n",
    "        \n",
    "    def  train(self):\n",
    "        #根据输入的训练数据更新节点链路权重\n",
    "        pass\n",
    "        \n",
    "    def  query(self, inputs):\n",
    "        #根据输入数据计算并输出答案\n",
    "        #计算中间层从输入层接收到的信号量\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        #计算中间层经过激活函数后形成的输出信号量\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        #计算最外层接收到的信号量\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #计算最外层神经元经过激活函数后输出的信号量\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        print(final_outputs)\n",
    "        return final_outputs\n",
    "\n",
    "'''\n",
    "我们尝试传入一些数据，让神经网络输出结果试试.\n",
    "程序当前运行结果并没有太大意义，但是至少表明，我们到目前为止写下的代码没有太大问题，\n",
    "'''\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "learning_rate = 0.3\n",
    "n = NeuralNetWork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c567cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0886809 , -0.05454698, -0.03660996])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.dot(n.wih, [1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df1b147",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2473939027.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\huawei\\AppData\\Local\\Temp\\ipykernel_9460\\2473939027.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    def__init__(self, inputnodes, hiddennodes, outputnodes, learningrates):\u001b[0m\n\u001b[1;37m                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#NeuralNetWork_init_detail\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "class NeuralNetWork:\n",
    "    def__init__(self, inputnodes, hiddennodes, outputnodes, learningrates):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learningrates\n",
    "        #输入层到中间层，中间层到输出层\n",
    "        self.wih = (np.random.normal(0.0, pow(self.hnodes - 0.5), (self.hnodes, self.inodes)))\n",
    "        self.who = (np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes)))\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targetsar -final_outputsl\n",
    "        hidden_errors = np.dot(self.who.T, output_errors*final_outputs*(1-final_outputs))\n",
    "        #根据误差计算链路权重的更新，然后把更新加到原来的链路权重上面\n",
    "        self.who += self.lr * np.dot((output_errors*final_outputsn*(1-final_outputs)),np.transpose(hidden_outputs))\n",
    "        self.whi += self.lr* np.dot((hidden_errors * hidden_outputs*(1-hidden_outputs)), np.transpose(inputs))\n",
    "        pass\n",
    "    def query(self, inputs):\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputsn)\n",
    "        print(final_outputs)\n",
    "        return final_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#一张图片由28*28=784个数值，因此我们需要让网络输入层具备28*28=784个输入节点\n",
    "inputs_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "n = NeuralNetWork(inputs_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "#读入训练数据\n",
    "training_data_file = open(\"dataset/mnist_test.csv\", \"r\")\n",
    "training_data_list = training_data_file.readlinens()\n",
    "training_data_file.close()\n",
    "\n",
    "#设定epochs，设定网络的循环训练次数\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(',')\n",
    "        inputs = (np.asfarray(all_values[1:]))/255.0 * 0.99 + 0.01\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "\n",
    "\n",
    "test_data_file = open(\"dataset/mnist_test.csv\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "scores = []\n",
    "\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(',')\n",
    "    correct_number = int(all_values)\n",
    "    print(\"该图片对应的数字为:\", correct_number)\n",
    "    inputs = (numpy.asfarray(all_values[1:])) / 255.0 * 0.99 + 0.01\n",
    "    #让网络判断图片对应的数字\n",
    "    outputs = n.query(inputs)\n",
    "    #找到数值最大的神经元对应的编号\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(\"网络认为图片的数字是：\", label)\n",
    "    if label == correct_number:\n",
    "        scores.append(1)\n",
    "    else:\n",
    "        scores.append(0)\n",
    "print(scores)\n",
    "\n",
    "#计算图片判断的成功率\n",
    "scores_array = numpy.asarray(scores)\n",
    "print(\"perfermance = \", scores_array.sum() / scores_array.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
